# ğŸš€ AI-Powered PDF Analysis Engine - 1B Challenge

> **Transform your PDF documents into intelligent insights with persona-driven analysis**

## ğŸŒŸ What This Does

This is a sophisticated AI system that analyzes PDF documents through the lens of specific personas and use cases. Think of it as having a smart assistant that reads through your documents and extracts exactly what matters to you, based on who you are and what you're trying to accomplish.

### âœ¨ Key Features
- **ğŸ§  Persona-Driven Analysis**: Content is filtered and ranked based on specific user personas
- **ğŸ“Š Intelligent Ranking**: Uses semantic similarity to find the most relevant sections
- **ğŸ“ Smart Summarization**: AI-powered content refinement and summarization
- **ğŸ”„ Batch Processing**: Handle multiple document collections automatically
- **ğŸ“‹ Structured Output**: Clean, consistent JSON results with metadata

## ğŸ—ï¸ Project Structure

```
ğŸ“ 1b/
â”œâ”€â”€ ğŸ³ Dockerfile                 # Container configuration
â”œâ”€â”€ ğŸ“‹ requirements.txt           # Python dependencies
â”œâ”€â”€ ğŸš€ run.py                     # Main execution script
â”œâ”€â”€ ğŸ”§ app.py                     # Core processing logic
â”œâ”€â”€ ğŸ“„ schemas.py                 # Data models & validation
â”œâ”€â”€ ğŸ“Š pdf_utils.py              # PDF extraction utilities
â”œâ”€â”€ ğŸ§  embedding.py              # AI embedding generation
â”œâ”€â”€ ğŸ“ˆ ranking.py                # Content ranking algorithm
â”œâ”€â”€ ğŸ“ summarise.py              # AI summarization engine
â”œâ”€â”€ ğŸ“‚ input/                    # Input documents & config
â”‚   â”œâ”€â”€ ğŸ“‹ challenge1b_input.json
â”‚   â””â”€â”€ ğŸ“„ *.pdf files
â””â”€â”€ ğŸ“‚ output/                   # Generated results
    â””â”€â”€ ğŸ“‹ challenge1b_output.json
```

## ğŸš€ Quick Start

### Using Docker (Recommended)

```bash
# Build the container
docker build -t pdf-analyzer .

# Run the analysis
docker run -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output pdf-analyzer
```

### Manual Setup

```bash
# Install dependencies
pip install -r requirements.txt

# Run the analysis
python run.py
```

## ğŸ“Š How It Works

### ğŸ”„ **Process Flow Diagram**

```mermaid
graph TD
    A[ğŸ“„ PDF Documents] --> B[ğŸ“‹ Input Configuration]
    B --> C[ğŸ”§ Document Processing]
    
    C --> D[ğŸ“„ PDF Text Extraction]
    D --> E[ğŸ“ Section Breakdown]
    E --> F[ğŸ§¹ Content Filtering]
    
    F --> G[ğŸ§  AI Embedding Generation]
    G --> H[ğŸ¯ Query Creation]
    H --> I[ğŸ“Š Similarity Computation]
    
    I --> J[ğŸ“ˆ Content Ranking]
    J --> K[ğŸ† Top Section Selection]
    K --> L[âœ¨ AI Summarization]
    
    L --> M[ğŸ“‹ Output Generation]
    M --> N[ğŸ’¾ JSON Results]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fff3e0
    style F fill:#fff3e0
    style G fill:#fce4ec
    style H fill:#fce4ec
    style I fill:#fce4ec
    style J fill:#e0f2f1
    style K fill:#e0f2f1
    style L fill:#f1f8e9
    style M fill:#e3f2fd
    style N fill:#e8f5e8
```

### ğŸ“‹ **Detailed Process Steps**

#### 1. **ğŸ“„ Document Processing** 
```
PDF Files â†’ Text Extraction â†’ Section Breakdown â†’ Content Filtering
```
- **Input**: Multiple PDF documents
- **Tool**: `pdfplumber` for text extraction
- **Output**: Structured sections with metadata
- **Filter**: Removes empty/invalid content

#### 2. **ğŸ§  AI-Powered Analysis**
```
Persona + Task â†’ Query Creation â†’ Embedding Generation â†’ Similarity Scoring
```
- **Query**: Combines persona role + job requirements
- **Model**: `sentence-transformers` (all-MiniLM-L6-v2)
- **Process**: Generates embeddings for query and all sections
- **Scoring**: Cosine similarity computation

#### 3. **ğŸ“ˆ Intelligent Ranking**
```
Similarity Scores â†’ Content Ranking â†’ Deduplication â†’ Top Selection
```
- **Algorithm**: Cosine similarity-based ranking
- **Deduplication**: Removes duplicate sections
- **Selection**: Top 5 most relevant sections
- **Output**: Ranked list with importance scores

#### 4. **âœ¨ Smart Summarization**
```
Top Sections â†’ T5 Model â†’ Content Refinement â†’ Summary Generation
```
- **Model**: T5-small transformer
- **Process**: Tokenization â†’ Summarization â†’ Refinement
- **Output**: Concise, relevant summaries
- **Quality**: Maintains context and key information

### ğŸ”§ **Technical Architecture**

```mermaid
graph LR
    subgraph "Input Layer"
        A1[ğŸ“„ PDFs] --> A2[ğŸ“‹ JSON Config]
    end
    
    subgraph "Processing Layer"
        B1[ğŸ“Š PDF Utils] --> B2[ğŸ§  Embedding]
        B2 --> B3[ğŸ“ˆ Ranking]
        B3 --> B4[âœ¨ Summarization]
    end
    
    subgraph "Output Layer"
        C1[ğŸ“‹ Schema Validation] --> C2[ğŸ’¾ JSON Output]
    end
    
    A1 --> B1
    A2 --> B1
    B4 --> C1
    
    style A1 fill:#e1f5fe
    style A2 fill:#f3e5f5
    style B1 fill:#e8f5e8
    style B2 fill:#fce4ec
    style B3 fill:#e0f2f1
    style B4 fill:#f1f8e9
    style C1 fill:#fff3e0
    style C2 fill:#e8f5e8
```

### âš¡ **Performance Flow**

```mermaid
sequenceDiagram
    participant U as User
    participant D as Docker
    participant R as run.py
    participant A as app.py
    participant AI as AI Models
    participant O as Output

    U->>D: docker run
    D->>R: Execute run.py
    R->>A: Process collection
    A->>AI: Load models
    AI-->>A: Models ready
    A->>A: Extract PDF content
    A->>AI: Generate embeddings
    AI-->>A: Embeddings ready
    A->>A: Rank content
    A->>AI: Summarize sections
    AI-->>A: Summaries ready
    A->>O: Generate JSON
    O-->>R: Save results
    R-->>D: Process complete
    D-->>U: Results available
```

## ğŸ“‹ Input Format

```json
{
  "challenge_info": {
    "challenge_id": "round_1b_002",
    "test_case_name": "travel_planner"
  },
  "documents": [
    {
      "filename": "document.pdf",
      "title": "Document Title"
    }
  ],
  "persona": {
    "role": "Travel Planner"
  },
  "job_to_be_done": {
    "task": "Plan a 4-day trip for 10 college friends"
  }
}
```

## ğŸ“¤ Output Format

```json
{
  "metadata": {
    "input_documents": ["list of processed files"],
    "persona": "User Persona",
    "job_to_be_done": "Task description",
    "processing_timestamp": "2024-01-01T12:00:00"
  },
  "extracted_sections": [
    {
      "document": "source.pdf",
      "section_title": "Section Title",
      "importance_rank": 1,
      "page_number": 1
    }
  ],
  "subsection_analysis": [
    {
      "document": "source.pdf",
      "refined_text": "AI-generated summary",
      "page_number": 1
    }
  ]
}
```

## ğŸ¯ Use Cases

### ğŸ§³ Travel Planning
- **Persona**: Travel Planner
- **Task**: Plan group trips, find attractions, restaurants
- **Documents**: Travel guides, city information, cultural guides

### ğŸ‘” Business Analysis
- **Persona**: Business Analyst
- **Task**: Extract market insights, competitive analysis
- **Documents**: Reports, whitepapers, industry studies

### ğŸ“š Academic Research
- **Persona**: Researcher
- **Task**: Literature review, data extraction
- **Documents**: Research papers, academic publications

## ğŸ”§ Technical Stack

- **ğŸ Python 3.10**: Core programming language
- **ğŸ“„ pdfplumber**: PDF text extraction
- **ğŸ§  sentence-transformers**: Semantic embeddings
- **ğŸ¤— transformers**: T5 summarization model
- **ğŸ“Š scipy**: Scientific computing and similarity calculations
- **ğŸ“‹ pydantic**: Data validation and serialization
- **ğŸ³ Docker**: Containerization for easy deployment

## ğŸš€ Performance Features

- **âš¡ Optimized Models**: Uses lightweight but effective AI models
- **ğŸ”„ Batch Processing**: Handles multiple document collections
- **ğŸ’¾ Memory Efficient**: Processes documents in chunks
- **ğŸ¯ Smart Filtering**: Removes irrelevant content automatically

## ğŸ” Troubleshooting

### Common Issues

1. **Model Download Failures**
   - Ensure stable internet connection
   - Check Docker build logs for download errors

2. **PDF Processing Issues**
   - Verify PDF files are not corrupted
   - Check file permissions in mounted volumes

3. **Memory Issues**
   - Large PDFs may require more Docker memory
   - Consider processing documents in smaller batches

## ğŸ¤ Contributing

This project is designed for specific use cases but can be extended for:
- Additional AI models
- New document formats
- Enhanced ranking algorithms
- Custom output formats

## ğŸ“„ License

This project is designed for educational and research purposes.

---

**ğŸ‰ Ready to transform your documents into intelligent insights? Let's get started!** 
